# Fall Detection System with YOLOv8 and State Machine

This repository implements a real-time fall detection system using the YOLOv8 object detection model and a state machine-based temporal logic. The application processes either local video files or RTSP streams, detects humans using YOLO, and determines fall events based on changes in bounding box orientation and time-based thresholds.

For any queries or contributions, feel free to reach out or open an issue.

## üì¶ Features

- üîç Real-time human detection using YOLOv8 (Ultralytics)
- üéØ Fall detection logic based on bounding box geometry and state transitions
- üß† State machine for robust event tracking: `start ‚Üí watchdog ‚Üí generateEventCheck`
- üì∏ Video feed recording at full FPS and controlled FPS
- üìù Annotated video output with timestamps and bounding box metadata
- üìÅ Support for both local video files and RTSP streams

---

## üìÅ Project Structure

```text
‚îú‚îÄ‚îÄ main.py                   # Entry point: captures video, handles state machine logic
‚îú‚îÄ‚îÄ config.json              # Configuration for video source, model, and parameters
‚îú‚îÄ‚îÄ perception_engine.py     # YOLOv8 inference engine and bounding box drawing
‚îú‚îÄ‚îÄ analysis_engine.py       # (Optional expansion) Analysis logic or helper states
‚îú‚îÄ‚îÄ helpers.py               # Utility functions for video metadata and state analysis
‚îú‚îÄ‚îÄ requirements.txt         # Python dependencies
‚îú‚îÄ‚îÄ livefeed/                # Output folder for generated videos and metadata
````

---

## ‚öôÔ∏è Installation

### 1. Clone the repository

```bash
git clone https://github.com/yourusername/fall-detection-yolov8.git
cd fall-detection-yolov8
```

### 2. Create a virtual environment

```bash
python -m venv venv
source venv/bin/activate  # On Windows use `venv\Scripts\activate`
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

---

## üß™ Configuration

Edit the `config.json` file to set:

```json
{
  "video": {
    "url": "D:/fall_detection_v2/fall.mp4",   // or RTSP stream
    "type": "local",                          // "local" or "rtsp"
    "fps": 24,
    "display": {
      "flag": true,
      "width": 640,
      "height": 360
    }
  },
  "perception_engine": {
    "model_name": "yolov8x.pt",
    "confidence_threshold": 0.75
  },
  "analysis_engine": {
    "state_tolerance_sec": 2,
    "fps": 2
  }
}
```

---

## üöÄ Usage

### Run the system:

```bash
python main.py
```

Press `q` at any time to quit the stream.

---

## üìÇ Outputs

After execution, you‚Äôll find the following outputs in the `livefeed/` directory:

* **`*_live_full_fps.mp4`** ‚Äî Raw recording at source FPS
* **`*_live_feed_controlled_fps.mp4`** ‚Äî Downsampled video for analysis
* **`*_annotated_controlled_fps.mp4`** ‚Äî Bounding boxes and state annotations
* **`*_meta_data.json`** ‚Äî Bounding box metadata
* **`*_events.json`** ‚Äî All detected fall events with timestamps

---

## üß† How It Works

1. **YOLOv8** detects people in each frame.
2. Bounding box width and height ratios are monitored.
3. A state machine transitions through:

   * `start` ‚Üí waiting for bounding box flip (width > height to height > width)
   * `watchdog` ‚Üí monitoring for duration (`state_tolerance_sec`)
   * `generateEventCheck` ‚Üí confirming and logging fall events
4. Events are saved and annotated on the video.

---

## üõ†Ô∏è Requirements

* Python 3.11
* NVIDIA GPU (recommended for YOLO inference)
* `yolov8x.pt` model from [Ultralytics](https://github.com/ultralytics/ultralytics)

---

## üìå TODO / Improvements

* Expand `analysis_engine.py` for modular event logic
* Add alert system (email, SMS)
* Add pose estimation or optical flow module
* Multi-person fall differentiation
* GUI for easier interaction

---

## üìÑ License

This project is released under the MIT License.

---

## üìà Results: YOLOv8s vs YOLOv8m vs YOLOv8l vs YOLOv8x

This section summarizes the GPU benchmarking results obtained from processing all CCTV clips across four YOLOv8 model sizes.

### **1. Average Inference Time (seconds per frame)**  
| Model      | Time (s) | Approx FPS |
|------------|----------|------------|
| YOLOv8s    | 0.018 s  | ~55 FPS    |
| YOLOv8m    | 0.025 s  | ~40 FPS    |
| YOLOv8l    | 0.019 s  | ~52 FPS    |
| YOLOv8x    | 0.032 s  | ~31 FPS    |

### **2. Average VRAM Usage (MB)**  
| Model      | Avg VRAM |
|------------|-----------|
| YOLOv8s    | ~230 MB   |
| YOLOv8m    | ~305 MB   |
| YOLOv8l    | ~400 MB   |
| YOLOv8x    | ~525 MB   |

### **3. Peak VRAM Usage (MB)**  
| Model      | Peak VRAM |
|------------|-----------|
| YOLOv8s    | ~370 MB   |
| YOLOv8m    | ~460 MB   |
| YOLOv8l    | ~570 MB   |
| YOLOv8x    | ~670 MB   |

### **4. Average GPU Utilization (%)**
| Model      | Utilization |
|------------|-------------|
| YOLOv8s    | ~8.5%       |
| YOLOv8m    | ~11.5%      |
| YOLOv8l    | ~17%        |
| YOLOv8x    | ~21%        |

### **5. Average Power Consumption (W)**
| Model      | Power (W) |
|------------|-----------|
| YOLOv8s    | ~56 W     |
| YOLOv8m    | ~59 W     |
| YOLOv8l    | ~62 W     |
| YOLOv8x    | ~70 W     |

---

## üìä Visual Summary

### **Average GPU Utilization**
![GPU Utilization](benchmark_results/bar_avg_util.png)

### **Average VRAM Usage**
![Average VRAM](benchmark_results/bar_avg_vram.png)

### **Peak VRAM Usage**
![Peak VRAM](benchmark_results/bar_peak_vram.png)

### **Average Inference Time**
![Inference Time](benchmark_results/bar_avg_inf_time.png)

### **Average Power**
![Power](benchmark_results/bar_avg_power.png)

---

## üß† Interpretation & Takeaways

- **YOLOv8s** is the most efficient model:
  - Fastest inference (~55 FPS)
  - Lowest GPU utilization
  - Lowest VRAM usage
  - Best choice for real-time fall detection on low or mid-range GPUs.

- **YOLOv8m** provides a balanced improvement in robustness while maintaining good speed (~40 FPS).

- **YOLOv8l** behaves unexpectedly fast in some clips due to batch-size and optimization effects and maintains moderate VRAM usage.

- **YOLOv8x** is the heaviest:
  - Highest VRAM consumption (~525‚Äì670 MB)
  - Highest power draw (~70 W)
  - Slowest (‚âà 31 FPS)
  - Only recommended if maximum accuracy is required.

Overall, **YOLOv8s** is the optimal choice for real-time CCTV fall detection.


---

## üë®‚Äçüíª Author

Muhammad Ammar Anees, Asad Soomro

